"""
Fusion Module
Implements fusion strategies to blend color-derived notes with melody model outputs.
"""

import logging
from typing import List, Dict, Any, Tuple, Optional
import numpy as np
from enum import Enum
import random


class FusionMode(Enum):
    """Available fusion modes."""
    HARD = "hard"
    SOFT = "soft"
    WEIGHTED = "weighted"
    ALTERNATING = "alternating"
    HARMONIC = "harmonic"


class FusionLayer:
    """Blends color-derived notes with melody model outputs."""
    
    def __init__(self, mode: FusionMode = FusionMode.SOFT):
        """
        Initialize fusion layer.
        
        Args:
            mode: Fusion mode to use
        """
        self.mode = mode
        self.logger = logging.getLogger(__name__)
        
        # Fusion parameters
        self.alpha = 0.7  # Weight for color influence in soft fusion
        self.temperature = 1.0  # Temperature for probability adjustment
        
    def fuse(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        weights: Optional[List[float]] = None,
        **kwargs
    ) -> List[int]:
        """
        Fuse color-derived notes with model-generated notes.
        
        Args:
            color_notes: Notes derived from color palette
            model_notes: Notes generated by melody model
            scale_intervals: Scale intervals in semitones
            weights: Optional weights for color notes
            
        Returns:
            Fused melody sequence
        """
        
        if self.mode == FusionMode.HARD:
            return self._hard_fusion(color_notes, model_notes, scale_intervals, weights)
        elif self.mode == FusionMode.SOFT:
            return self._soft_fusion(color_notes, model_notes, scale_intervals, weights)
        elif self.mode == FusionMode.WEIGHTED:
            return self._weighted_fusion(color_notes, model_notes, scale_intervals, weights)
        elif self.mode == FusionMode.ALTERNATING:
            return self._alternating_fusion(color_notes, model_notes, scale_intervals, weights)
        elif self.mode == FusionMode.HARMONIC:
            return self._harmonic_fusion(color_notes, model_notes, scale_intervals, weights)
        else:
            raise ValueError(f"Unknown fusion mode: {self.mode}")
    
    def _hard_fusion(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        weights: Optional[List[float]] = None
    ) -> List[int]:
        """
        Hard fusion: Snap generated notes to nearest palette pitch classes.
        """
        
        fused_notes = []
        
        for note in model_notes:
            # Find the closest color note
            if color_notes:
                distances = [abs(note - color_note) for color_note in color_notes]
                closest_color_note = color_notes[np.argmin(distances)]
                
                # Use the closest color note
                fused_notes.append(closest_color_note)
            else:
                fused_notes.append(note)
        
        self.logger.info("Applied hard fusion")
        return fused_notes
    
    def _soft_fusion(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        weights: Optional[List[float]] = None
    ) -> List[int]:
        """
        Soft fusion: Reweight sampling probabilities based on distance from palette.
        """
        
        fused_notes = []
        num_scale_notes = len(scale_intervals)
        
        for i, note in enumerate(model_notes):
            if not color_notes:
                fused_notes.append(note)
                continue
            
            # Create probability distribution for all scale notes
            probabilities = np.ones(num_scale_notes) / num_scale_notes
            
            # Adjust probabilities based on distance from color notes
            for j in range(num_scale_notes):
                min_distance = min([abs(j - color_note) for color_note in color_notes])
                
                # Increase probability for notes closer to color palette
                distance_factor = np.exp(-min_distance / self.temperature)
                probabilities[j] *= distance_factor
            
            # Normalize probabilities
            probabilities = probabilities / np.sum(probabilities)
            
            # Blend with original model preference
            original_prob = np.zeros(num_scale_notes)
            if 0 <= note < num_scale_notes:
                original_prob[note] = 1.0
            
            final_probabilities = (
                self.alpha * probabilities + 
                (1 - self.alpha) * original_prob
            )
            final_probabilities = final_probabilities / np.sum(final_probabilities)
            
            # Sample from blended distribution
            fused_note = np.random.choice(num_scale_notes, p=final_probabilities)
            fused_notes.append(fused_note)
        
        self.logger.info("Applied soft fusion")
        return fused_notes
    
    def _weighted_fusion(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        weights: Optional[List[float]] = None
    ) -> List[int]:
        """
        Weighted fusion: Use color weights to influence note selection.
        """
        
        if weights is None:
            weights = [1.0] * len(color_notes)
        
        fused_notes = []
        
        for i, note in enumerate(model_notes):
            if not color_notes:
                fused_notes.append(note)
                continue
            
            # Decide whether to use color note or model note based on position and weights
            color_influence = self._calculate_color_influence(i, len(model_notes), weights)
            
            if random.random() < color_influence:
                # Use weighted random selection from color notes
                if len(weights) == len(color_notes):
                    normalized_weights = np.array(weights) / np.sum(weights)
                    selected_color_note = np.random.choice(color_notes, p=normalized_weights)
                else:
                    selected_color_note = random.choice(color_notes)
                
                fused_notes.append(selected_color_note)
            else:
                fused_notes.append(note)
        
        self.logger.info("Applied weighted fusion")
        return fused_notes
    
    def _alternating_fusion(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        weights: Optional[List[float]] = None
    ) -> List[int]:
        """
        Alternating fusion: Alternate between color notes and model notes.
        """
        
        fused_notes = []
        color_index = 0
        
        for i, note in enumerate(model_notes):
            if not color_notes:
                fused_notes.append(note)
                continue
            
            # Alternate pattern: every 3rd note uses color palette
            if (i + 1) % 3 == 0:
                fused_notes.append(color_notes[color_index % len(color_notes)])
                color_index += 1
            else:
                fused_notes.append(note)
        
        self.logger.info("Applied alternating fusion")
        return fused_notes
    
    def _harmonic_fusion(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        weights: Optional[List[float]] = None
    ) -> List[int]:
        """
        Harmonic fusion: Create harmonic relationships between color and model notes.
        """
        
        fused_notes = []
        
        for i, note in enumerate(model_notes):
            if not color_notes:
                fused_notes.append(note)
                continue
            
            # Find harmonic intervals (thirds, fifths, octaves)
            harmonic_intervals = [2, 4, 7]  # Third, fifth, octave in scale degrees
            
            # Select a color note
            base_color_note = color_notes[i % len(color_notes)]
            
            # Decide whether to use the color note or a harmonic interval
            if random.random() < 0.6:  # 60% chance to use color note directly
                fused_notes.append(base_color_note)
            else:
                # Use harmonic interval
                interval = random.choice(harmonic_intervals)
                harmonic_note = (base_color_note + interval) % len(scale_intervals)
                fused_notes.append(harmonic_note)
        
        self.logger.info("Applied harmonic fusion")
        return fused_notes
    
    def _calculate_color_influence(
        self, 
        position: int, 
        total_length: int, 
        weights: List[float]
    ) -> float:
        """Calculate the influence of color at a given position in the melody."""
        
        # Base influence starts high and decreases over time
        base_influence = 1.0 - (position / total_length) * 0.5
        
        # Modify by average weight
        weight_factor = np.mean(weights) if weights else 0.5
        
        # Add some variation
        variation = 0.1 * np.sin(position * np.pi / 8)
        
        return max(0.1, min(0.9, base_influence * weight_factor + variation))
    
    def set_fusion_parameters(self, **kwargs):
        """Update fusion parameters."""
        
        if 'alpha' in kwargs:
            self.alpha = max(0.0, min(1.0, kwargs['alpha']))
        
        if 'temperature' in kwargs:
            self.temperature = max(0.1, kwargs['temperature'])
        
        self.logger.info(f"Updated fusion parameters: alpha={self.alpha}, temperature={self.temperature}")


class AdaptiveFusion:
    """Adaptive fusion that selects the best fusion mode based on image characteristics."""
    
    def __init__(self):
        """Initialize adaptive fusion."""
        self.logger = logging.getLogger(__name__)
        
        # Available fusion layers
        self.fusion_layers = {
            mode: FusionLayer(mode) for mode in FusionMode
        }
    
    def select_fusion_mode(self, image_features: Dict[str, Any]) -> FusionMode:
        """
        Select the best fusion mode based on image characteristics.
        
        Args:
            image_features: Extracted image features
            
        Returns:
            Selected fusion mode
        """
        
        # Decision rules based on image characteristics
        
        # High color harmony -> use soft fusion
        if image_features.get('color_harmony_score', 0.5) > 0.7:
            return FusionMode.SOFT
        
        # High complexity -> use hard fusion for stability
        if image_features.get('complexity_score', 0.5) > 0.7:
            return FusionMode.HARD
        
        # High symmetry -> use harmonic fusion
        if image_features.get('symmetry_score', 0.5) > 0.6:
            return FusionMode.HARMONIC
        
        # High saturation -> use weighted fusion
        if image_features.get('mean_saturation', 0.5) > 0.6:
            return FusionMode.WEIGHTED
        
        # Default to alternating fusion
        return FusionMode.ALTERNATING
    
    def fuse(
        self,
        color_notes: List[int],
        model_notes: List[int],
        scale_intervals: List[int],
        image_features: Dict[str, Any],
        weights: Optional[List[float]] = None,
        fusion_mode: Optional[FusionMode] = None
    ) -> Tuple[List[int], FusionMode]:
        """
        Perform adaptive fusion.
        
        Args:
            color_notes: Notes derived from colors
            model_notes: Notes from melody model
            scale_intervals: Scale intervals
            image_features: Image features for mode selection
            weights: Optional color weights
            fusion_mode: Override automatic mode selection
            
        Returns:
            Tuple of (fused_notes, selected_mode)
        """
        
        # Select fusion mode
        if fusion_mode is None:
            selected_mode = self.select_fusion_mode(image_features)
        else:
            selected_mode = fusion_mode
        
        # Apply fusion
        fusion_layer = self.fusion_layers[selected_mode]
        fused_notes = fusion_layer.fuse(
            color_notes, model_notes, scale_intervals, weights
        )
        
        self.logger.info(f"Applied adaptive fusion with mode: {selected_mode.value}")
        
        return fused_notes, selected_mode


class FusionAnalyzer:
    """Analyzes and evaluates fusion results."""
    
    def __init__(self):
        """Initialize fusion analyzer."""
        self.logger = logging.getLogger(__name__)
    
    def analyze_fusion_quality(
        self,
        original_notes: List[int],
        fused_notes: List[int],
        color_notes: List[int]
    ) -> Dict[str, float]:
        """
        Analyze the quality of fusion results.
        
        Args:
            original_notes: Original model-generated notes
            fused_notes: Fused notes
            color_notes: Color-derived notes
            
        Returns:
            Dictionary with quality metrics
        """
        
        # Color preservation (how much color influence is retained)
        color_preservation = self._calculate_color_preservation(fused_notes, color_notes)
        
        # Musical coherence (melodic intervals and flow)
        coherence = self._calculate_melodic_coherence(fused_notes)
        
        # Diversity (note variety)
        diversity = self._calculate_note_diversity(fused_notes)
        
        # Similarity to original (how much original melody is preserved)
        original_similarity = self._calculate_similarity(original_notes, fused_notes)
        
        return {
            'color_preservation': color_preservation,
            'melodic_coherence': coherence,
            'note_diversity': diversity,
            'original_similarity': original_similarity,
            'overall_quality': (color_preservation + coherence + diversity) / 3.0
        }
    
    def _calculate_color_preservation(
        self, 
        fused_notes: List[int], 
        color_notes: List[int]
    ) -> float:
        """Calculate how well color notes are preserved in fusion."""
        
        if not color_notes or not fused_notes:
            return 0.0
        
        color_set = set(color_notes)
        fused_set = set(fused_notes)
        
        # Ratio of color notes that appear in fused result
        intersection = len(color_set.intersection(fused_set))
        preservation = intersection / len(color_set)
        
        return preservation
    
    def _calculate_melodic_coherence(self, notes: List[int]) -> float:
        """Calculate melodic coherence based on interval patterns."""
        
        if len(notes) < 2:
            return 1.0
        
        # Calculate intervals
        intervals = [abs(notes[i+1] - notes[i]) for i in range(len(notes)-1)]
        
        # Prefer smaller intervals (stepwise motion)
        small_intervals = sum(1 for interval in intervals if interval <= 2)
        coherence = small_intervals / len(intervals)
        
        # Penalize large jumps
        large_jumps = sum(1 for interval in intervals if interval > 4)
        jump_penalty = large_jumps / len(intervals) * 0.5
        
        return max(0.0, coherence - jump_penalty)
    
    def _calculate_note_diversity(self, notes: List[int]) -> float:
        """Calculate note diversity (number of unique notes)."""
        
        if not notes:
            return 0.0
        
        unique_notes = len(set(notes))
        max_diversity = min(len(notes), 7)  # Assume 7-note scale
        
        return unique_notes / max_diversity
    
    def _calculate_similarity(self, notes1: List[int], notes2: List[int]) -> float:
        """Calculate similarity between two note sequences."""
        
        if not notes1 or not notes2:
            return 0.0
        
        # Simple similarity based on common notes in same positions
        min_length = min(len(notes1), len(notes2))
        matches = sum(1 for i in range(min_length) if notes1[i] == notes2[i])
        
        return matches / min_length if min_length > 0 else 0.0